Homework 3
================
Connie Zhang
10/09/2019

# Problem 1

``` r
instacart = 
  library(p8105.datasets)
  data("instacart")
```

  - The instacart dataset has 1384617 observations, with 15 variables.
    Key variables include order details, product name, aisle, and
    department with respective numeric IDs associated with them. For
    example, the first order
is

| order\_id | product\_id | add\_to\_cart\_order | reordered | user\_id | eval\_set | order\_number | order\_dow | order\_hour\_of\_day | days\_since\_prior\_order | product\_name    | aisle\_id | department\_id | aisle  | department |
| --------: | ----------: | -------------------: | --------: | -------: | :-------- | ------------: | ---------: | -------------------: | ------------------------: | :--------------- | --------: | -------------: | :----- | :--------- |
|         1 |       49302 |                    1 |         1 |   112108 | train     |             4 |          4 |                   10 |                         9 | Bulgarian Yogurt |       120 |             16 | yogurt | dairy eggs |

It is an order of bulgarian yogurt, by user id 112108, placed on 10am on
4th day of week, Wednesday. The yogurt is in aisle 120, in the dairy
eggs department. He purchased this product 4 times before and his last
order was 9 days ago.

Number of aisles and which aisles the most items are ordered from:

``` r
instacart %>%
  count(aisle_id, name = "n") %>% 
arrange (desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle_id      n
    ##       <int>  <int>
    ##  1       83 150609
    ##  2       24 150473
    ##  3      123  78493
    ##  4      120  55240
    ##  5       21  41699
    ##  6      115  36617
    ##  7       84  32644
    ##  8      107  31269
    ##  9       91  26240
    ## 10      112  23635
    ## # … with 124 more rows

Plot that shows the number of items ordered in each aisle, limited to
aisles with more than 10000 items ordered:

``` r
instacart %>%
  group_by(aisle) %>%
  summarize(aisle_n = n()) %>%
  filter(aisle_n >10000) %>%
  arrange (desc(aisle_n)) %>%
  ggplot(aes(x = aisle, y = aisle_n, color = aisle)) + ggtitle("Quantity of Items Ordered in Each Aisle") +
  theme(plot.title = element_text(hjust = 0.5))+ geom_point() + 
  labs(       x = "aisle",
              y = "number of items ordered in aisle") + viridis::scale_color_viridis(discrete = TRUE) + theme(legend.position = "none", axis.text.x = element_text(angle=70, hjust=1))
```

![](p8105_hw3_cz2540_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

Table that shows three most popular items in the aisles “baking
ingredients”, “dog food care”, and “packaged vegetables fruits”. Include
the number of times each item is ordered in your table:

``` r
table_popular = 
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care","packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarize(n = n()) %>%
top_n(3) %>%
arrange(desc(n)) %>%
knitr::kable()
```

    ## Selecting by n

``` r
table_popular
```

| aisle                      | product\_name                                 |    n |
| :------------------------- | :-------------------------------------------- | ---: |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |
| baking ingredients         | Light Brown Sugar                             |  499 |
| baking ingredients         | Pure Baking Soda                              |  387 |
| baking ingredients         | Cane Sugar                                    |  336 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |
| dog food care              | Small Dog Biscuits                            |   26 |

Table that shows the mean hour of the day at which Pink Lady Apples and
Coffee Ice Cream are ordered on each day of the week; format this table
for human readers (i.e. produce a 2 x 7 table):

``` r
table_icecream_apple = instacart %>%
  select(product_name, order_dow, order_hour_of_day) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  mutate(order_dow = recode(order_dow, "0" = "Sunday", "1" = "Monday", "2" = "Tuesday", "3" = "Wednesday", "4" = "Thursday", "5" = "Friday", "6" = "Saturday")) %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  pivot_wider(names_from = "order_dow", values_from = "mean_hour") %>%
knitr::kable(digits = 2)
```

# Problem 2

  - How to arrange from poor to excellent \*
  - How to take out dashes in the columns that separate county and state
    \*

<!-- end list -->

``` r
#import data
data("brfss_smart2010")

#clean data
cleanbrfss_data = brfss_smart2010 %>%
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  filter(response %in% c("Poor", "Fair","Good", "Very good", "Excellent")) %>% 
  mutate(response = factor(response, levels = c("Poor", "Fair","Good", "Very good", "Excellent"))) 
```

States that were observed in 2002 at 7 or more locations:

``` r
cleanbrfss_data %>% 
  filter(year == 2002) %>% 
  group_by(state) %>% 
  summarize(n_location = n_distinct(county)) %>% 
  filter(n_location >= 7) %>%
  arrange(n_location)
```

    ## # A tibble: 6 x 2
    ##   state n_location
    ##   <chr>      <int>
    ## 1 CT             7
    ## 2 FL             7
    ## 3 NC             7
    ## 4 MA             8
    ## 5 NJ             8
    ## 6 PA            10

  - In 2002, Connecticut, Florida, Massachusetts, North Carolina, New
    Jersey, and Pennsylvania were observed at 7 or more locations.

States that were observed in 2010 at 7 or more locations:

``` r
cleanbrfss_data %>% 
  filter(year == 2010) %>% 
  group_by(state) %>% 
  summarize(n_location = n_distinct(county)) %>% 
  filter(n_location >= 7) %>%
  arrange(n_location)
```

    ## # A tibble: 14 x 2
    ##    state n_location
    ##    <chr>      <int>
    ##  1 CO             7
    ##  2 PA             7
    ##  3 SC             7
    ##  4 OH             8
    ##  5 MA             9
    ##  6 NY             9
    ##  7 NE            10
    ##  8 WA            10
    ##  9 CA            12
    ## 10 MD            12
    ## 11 NC            12
    ## 12 TX            16
    ## 13 NJ            19
    ## 14 FL            41

  - In 2010, Colorado, Pennsylvania, South Carolina, Ohio, Maryland, New
    York, Nebraska, Washington, California, Maryland, North Carolina,
    Texas, New Jersey, and Florida were observed in 7 or more locations.

Dataset limited to Excellent responses, and contains, year, state,
averages of the data\_value across locations within a state:

``` r
brfss_excellent = cleanbrfss_data %>% 
  filter(response == "Excellent") %>%
  group_by(state, year, response) %>% 
  summarize(avg_data = mean(data_value))
```

“Spaghetti” plot of this average value over time within a state (that
is, make a plot showing a line for each state across years:
