Homework 3
================
Connie Zhang
10/09/2019

# Problem 1

``` r
instacart = 
  library(p8105.datasets)
  data("instacart")
```

  - The instacart dataset has 1384617 observations, with 15 variables.
    Key variables include order details, product name, aisle, and
    department with respective numeric IDs associated with them. For
    example, the first order
is

| order\_id | product\_id | add\_to\_cart\_order | reordered | user\_id | eval\_set | order\_number | order\_dow | order\_hour\_of\_day | days\_since\_prior\_order | product\_name    | aisle\_id | department\_id | aisle  | department |
| --------: | ----------: | -------------------: | --------: | -------: | :-------- | ------------: | ---------: | -------------------: | ------------------------: | :--------------- | --------: | -------------: | :----- | :--------- |
|         1 |       49302 |                    1 |         1 |   112108 | train     |             4 |          4 |                   10 |                         9 | Bulgarian Yogurt |       120 |             16 | yogurt | dairy eggs |

It is an order of bulgarian yogurt, by user id 112108, placed on 10am on
4th day of week, Wednesday. The yogurt is in aisle 120, in the dairy
eggs department. He purchased this product 4 times before and his last
order was 9 days ago.

Number of aisles and which aisles the most items are ordered from:

``` r
instacart %>%
  count(aisle_id, name = "n") %>% 
arrange (desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle_id      n
    ##       <int>  <int>
    ##  1       83 150609
    ##  2       24 150473
    ##  3      123  78493
    ##  4      120  55240
    ##  5       21  41699
    ##  6      115  36617
    ##  7       84  32644
    ##  8      107  31269
    ##  9       91  26240
    ## 10      112  23635
    ## # … with 124 more rows

Plot that shows the number of items ordered in each aisle, limited to
aisles with more than 10000 items ordered:

``` r
instacart %>%
  group_by(aisle) %>%
  summarize(aisle_n = n()) %>%
  filter(aisle_n >10000) %>%
  arrange (desc(aisle_n)) %>%
  ggplot(aes(x = aisle, y = aisle_n, color = aisle)) + ggtitle("Quantity of Items Ordered in Each Aisle") +
  theme(plot.title = element_text(hjust = 0.5))+ geom_point() + 
  labs(       x = "aisle",
              y = "number of items ordered in aisle") + viridis::scale_color_viridis(discrete = TRUE) + theme(legend.position = "none", axis.text.x = element_text(angle=70, hjust=1))
```

![](p8105_hw3_cz2540_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

Table that shows three most popular items in the aisles “baking
ingredients”, “dog food care”, and “packaged vegetables fruits”. Include
the number of times each item is ordered in your table:

``` r
table_popular = 
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care","packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarize(n = n()) %>%
top_n(3) %>%
arrange(desc(n)) %>%
knitr::kable()
```

    ## Selecting by n

``` r
table_popular
```

| aisle                      | product\_name                                 |    n |
| :------------------------- | :-------------------------------------------- | ---: |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |
| baking ingredients         | Light Brown Sugar                             |  499 |
| baking ingredients         | Pure Baking Soda                              |  387 |
| baking ingredients         | Cane Sugar                                    |  336 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |
| dog food care              | Small Dog Biscuits                            |   26 |

Table that shows the mean hour of the day at which Pink Lady Apples and
Coffee Ice Cream are ordered on each day of the week; format this table
for human readers (i.e. produce a 2 x 7 table):

``` r
table_icecream_apple = instacart %>%
  select(product_name, order_dow, order_hour_of_day) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  mutate(order_dow = recode(order_dow, "0" = "Sunday", "1" = "Monday", "2" = "Tuesday", "3" = "Wednesday", "4" = "Thursday", "5" = "Friday", "6" = "Saturday")) %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  pivot_wider(names_from = "order_dow", values_from = "mean_hour") %>%
knitr::kable(digits = 2)
```

# Problem 2

``` r
data("brfss_smart2010") #load data
```

``` r
cleanbrfss_data = brfss_smart2010 %>%
janitor::clean_names() %>%
separate(locationdesc, into = c("state", "county"), sep= 3) %>% 
mutate(county= stringr::str_replace(county, "- ", "")) %>% 
filter(topic == "Overall Health", response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>%
mutate(response = factor(response, levels = c("Poor","Fair","Good","Very good", "Excellent" ))) %>%
select(-state, -location_id, -data_value_footnote_symbol, -data_value_footnote)
cleanbrfss_data
```

    ## # A tibble: 10,625 x 20
    ##     year locationabbr county class topic question response sample_size
    ##    <int> <chr>        <chr>  <chr> <chr> <chr>    <fct>          <int>
    ##  1  2010 AL           Jeffe… Heal… Over… How is … Excelle…          94
    ##  2  2010 AL           Jeffe… Heal… Over… How is … Very go…         148
    ##  3  2010 AL           Jeffe… Heal… Over… How is … Good             208
    ##  4  2010 AL           Jeffe… Heal… Over… How is … Fair             107
    ##  5  2010 AL           Jeffe… Heal… Over… How is … Poor              45
    ##  6  2010 AL           Mobil… Heal… Over… How is … Excelle…          91
    ##  7  2010 AL           Mobil… Heal… Over… How is … Very go…         177
    ##  8  2010 AL           Mobil… Heal… Over… How is … Good             224
    ##  9  2010 AL           Mobil… Heal… Over… How is … Fair             120
    ## 10  2010 AL           Mobil… Heal… Over… How is … Poor              66
    ## # … with 10,615 more rows, and 12 more variables: data_value <dbl>,
    ## #   confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, question_id <chr>,
    ## #   respid <chr>, geo_location <chr>

States that were observed in 2002 at 7 or more locations:

``` r
cleanbrfss_data %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarize(n_location = n_distinct(county)) %>% 
  filter(n_location >= 7) %>%
  arrange(n_location)
```

    ## # A tibble: 6 x 2
    ##   locationabbr n_location
    ##   <chr>             <int>
    ## 1 CT                    7
    ## 2 FL                    7
    ## 3 NC                    7
    ## 4 MA                    8
    ## 5 NJ                    8
    ## 6 PA                   10

\`\`\` \* In 2002, Connecticut, Florida, Massachusetts, North Carolina,
New Jersey, and Pennsylvania were observed at 7 or more locations.

States that were observed in 2010 at 7 or more locations:

``` r
cleanbrfss_data %>% 
  filter(year == 2010) %>% 
  group_by(locationabbr) %>% 
  summarize(n_location = n_distinct(county)) %>% 
  filter(n_location >= 7) %>%
  arrange(n_location)
```

    ## # A tibble: 14 x 2
    ##    locationabbr n_location
    ##    <chr>             <int>
    ##  1 CO                    7
    ##  2 PA                    7
    ##  3 SC                    7
    ##  4 OH                    8
    ##  5 MA                    9
    ##  6 NY                    9
    ##  7 NE                   10
    ##  8 WA                   10
    ##  9 CA                   12
    ## 10 MD                   12
    ## 11 NC                   12
    ## 12 TX                   16
    ## 13 NJ                   19
    ## 14 FL                   41

``` r
cleanbrfss_data
```

    ## # A tibble: 10,625 x 20
    ##     year locationabbr county class topic question response sample_size
    ##    <int> <chr>        <chr>  <chr> <chr> <chr>    <fct>          <int>
    ##  1  2010 AL           Jeffe… Heal… Over… How is … Excelle…          94
    ##  2  2010 AL           Jeffe… Heal… Over… How is … Very go…         148
    ##  3  2010 AL           Jeffe… Heal… Over… How is … Good             208
    ##  4  2010 AL           Jeffe… Heal… Over… How is … Fair             107
    ##  5  2010 AL           Jeffe… Heal… Over… How is … Poor              45
    ##  6  2010 AL           Mobil… Heal… Over… How is … Excelle…          91
    ##  7  2010 AL           Mobil… Heal… Over… How is … Very go…         177
    ##  8  2010 AL           Mobil… Heal… Over… How is … Good             224
    ##  9  2010 AL           Mobil… Heal… Over… How is … Fair             120
    ## 10  2010 AL           Mobil… Heal… Over… How is … Poor              66
    ## # … with 10,615 more rows, and 12 more variables: data_value <dbl>,
    ## #   confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, question_id <chr>,
    ## #   respid <chr>, geo_location <chr>

  - In 2010, Colorado, Pennsylvania, South Carolina, Ohio, Maryland, New
    York, Nebraska, Washington, California, Maryland, North Carolina,
    Texas, New Jersey, and Florida were observed in 7 or more locations.

Dataset limited to Excellent responses, and contains, year, state,
averages of the data\_value across locations within a state:

``` r
brfss_excellent = cleanbrfss_data %>% 
  filter(response == "Excellent") %>%
  group_by(year, locationabbr, county) %>% 
  summarize(avg_data = mean(data_value))
brfss_excellent
```

    ## # A tibble: 2,125 x 4
    ## # Groups:   year, locationabbr [443]
    ##     year locationabbr county                 avg_data
    ##    <int> <chr>        <chr>                     <dbl>
    ##  1  2002 AK           Anchorage Municipality     27.9
    ##  2  2002 AL           Jefferson County           18.5
    ##  3  2002 AR           Pulaski County             24.1
    ##  4  2002 AZ           Maricopa County            21.6
    ##  5  2002 AZ           Pima County                26.6
    ##  6  2002 CA           Los Angeles County         22.7
    ##  7  2002 CO           Adams County               21.2
    ##  8  2002 CO           Arapahoe County            25.5
    ##  9  2002 CO           Denver County              22.2
    ## 10  2002 CO           Jefferson County           23.4
    ## # … with 2,115 more rows

“Spaghetti” plot of this average value over time within a state (that
is, make a plot showing a line for each state across years):

``` r
brfss_excellent %>%
ggplot(aes(x = year , y = avg_data, color= locationabbr)) + geom_line() + 
labs(title = "Average Value Over Time Within Each State", x = "Year", y = "Average Value") + 
viridis::scale_color_viridis(discrete = TRUE) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, size = 14), axis.text.x = element_text(angle=70, hjust=1)) + theme(legend.position = "right", axis.text.x = element_text(angle=70, hjust=1))
```

![](p8105_hw3_cz2540_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

Two-panel plot showing, for the years 2006, and 2010, distribution of
data\_value for responses (“Poor” to “Excellent”) among locations in NY
State:

``` r
combined_plot = 
cleanbrfss_data %>%
  filter(topic == "Overall Health", 
  year == "2006"| 
  year == "2010",
  locationabbr == "NY") 
combined_plot
```

    ## # A tibble: 75 x 20
    ##     year locationabbr county class topic question response sample_size
    ##    <int> <chr>        <chr>  <chr> <chr> <chr>    <fct>          <int>
    ##  1  2010 NY           Bronx… Heal… Over… How is … Excelle…          61
    ##  2  2010 NY           Bronx… Heal… Over… How is … Very go…         105
    ##  3  2010 NY           Bronx… Heal… Over… How is … Good             151
    ##  4  2010 NY           Bronx… Heal… Over… How is … Fair              86
    ##  5  2010 NY           Bronx… Heal… Over… How is … Poor              31
    ##  6  2010 NY           Erie … Heal… Over… How is … Excelle…          69
    ##  7  2010 NY           Erie … Heal… Over… How is … Very go…         169
    ##  8  2010 NY           Erie … Heal… Over… How is … Good             154
    ##  9  2010 NY           Erie … Heal… Over… How is … Fair              69
    ## 10  2010 NY           Erie … Heal… Over… How is … Poor              16
    ## # … with 65 more rows, and 12 more variables: data_value <dbl>,
    ## #   confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, question_id <chr>,
    ## #   respid <chr>, geo_location <chr>

``` r
twopanel_plot = combined_plot %>% 
  ggplot(aes(x = response, y = data_value, color = response))+
  geom_boxplot()+
  facet_grid(. ~year) 
twopanel_plot
```

![](p8105_hw3_cz2540_files/figure-gfm/unnamed-chunk-12-1.png)<!-- -->

# Problem 3

``` r
acc_data = 
  read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer (
    activity_1:activity_1440, names_to = "activity_min", values_to = "activity_count") %>%
  mutate(activity_min = stringr::str_replace(activity_min, "activity_", " "), weekkday = day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"), weekend = day %in% c("Saturday", "Sunday")) %>%
select (-day_id)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
acc_data
```

    ## # A tibble: 50,400 x 6
    ##     week day    activity_min activity_count weekkday weekend
    ##    <dbl> <chr>  <chr>                 <dbl> <lgl>    <lgl>  
    ##  1     1 Friday " 1"                   88.4 TRUE     FALSE  
    ##  2     1 Friday " 2"                   82.2 TRUE     FALSE  
    ##  3     1 Friday " 3"                   64.4 TRUE     FALSE  
    ##  4     1 Friday " 4"                   70.0 TRUE     FALSE  
    ##  5     1 Friday " 5"                   75.0 TRUE     FALSE  
    ##  6     1 Friday " 6"                   66.3 TRUE     FALSE  
    ##  7     1 Friday " 7"                   53.8 TRUE     FALSE  
    ##  8     1 Friday " 8"                   47.8 TRUE     FALSE  
    ##  9     1 Friday " 9"                   55.5 TRUE     FALSE  
    ## 10     1 Friday " 10"                  43.0 TRUE     FALSE  
    ## # … with 50,390 more rows

  - This dataset has 50400 observations with 6 variables. Key variables
    include order details, product name, aisle, and department with
    respective numeric IDs associated with them. Variables include the
    day of the week the activity occurs, the minute in which activity is
    being recorded, and the acceleration count of the 63 y/o male
    patient’s body at each minute. Additionally, the dataset includes
    variables that categorize if the date/minute/count being logged is a
    weekend or weekday.

Aggregate dataset across minutes to create a total activity variable for
each day, and create a table showing these totals:

``` r
total_activity = acc_data %>%
  group_by(day) %>%
  summarize(total_activity = mean (activity_count)) %>%
  arrange(desc(total_activity)) %>%
  knitr::kable()
total_activity
```

| day       | total\_activity |
| :-------- | --------------: |
| Friday    |        318.2931 |
| Wednesday |        295.8017 |
| Thursday  |        290.4376 |
| Sunday    |        266.5574 |
| Monday    |        258.1526 |
| Tuesday   |        249.8942 |
| Saturday  |        190.1718 |

Single-panel plot that shows the 24-hour activity time courses for each
day and use color to indicate day of the week:

  - Patterns or conclusions you can make based on this graph
